import asyncio
import os
import sys
import pandas as pd
from datetime import datetime, timedelta, timezone
from loguru import logger

from src.orchestrator import Orchestrator
from .session import BacktestSession
import src.utils.telegram_notify as tg

tg.send_telegram_message = lambda message: None
logger.remove()
logger.add(sys.stdout, format="<green>{time:HH:mm:ss}</green> | <level>{message}</level>", level="INFO")

async def run_backtest(params=None):
    history_path = "data/history"
    test_db_path = "data/backtest_results.db"
    
    if not os.path.exists(history_path):
        logger.error(f"–ü–∞–ø–∫–∞ {history_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return

    # 1. –ü–û–ò–°–ö –§–ê–ô–õ–û–í
    all_files = os.listdir(history_path)
    # –ò—â–µ–º –≤—Å–µ —Ç–∏–∫–µ—Ä—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –û–ë–ê —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ (15 –∏ 60)
    t15 = {f.split('_')[0] for f in all_files if f.endswith('_15.csv')}
    t60 = {f.split('_')[0] for f in all_files if f.endswith('_60.csv')}
    tickers = sorted(list(t15.intersection(t60)))
    
    if not tickers:
        logger.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (15 –∏ 60 –º–∏–Ω) –≤ {history_path}!")
        return
        
    logger.info(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è {len(tickers)} –º–æ–Ω–µ—Ç...")

    history = {}
    history_starts = []
    history_ends = []

    # 2. –ó–ê–ì–†–£–ó–ö–ê
    for t in tickers:
        for tf in ["15", "60"]:
            path = f"{history_path}/{t}_{tf}.csv"
            try:
                df = pd.read_csv(path)
                
                # –ê–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
                time_col = 'time_ms' if 'time_ms' in df.columns else 'time'
                
                if time_col == 'time_ms':
                    # –ó–∞–º–µ–Ω—è–µ–º utc=True –Ω–∞ .dt.tz_localize(None)
                    df['time'] = pd.to_datetime(df['time_ms'], unit='ms').dt.tz_localize(None)
                else:
                    df['time'] = pd.to_datetime(df['time']).dt.tz_localize(None)

                df = df.sort_values('time').reset_index(drop=True)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
                if df.empty:
                    continue

                history[f"{t}_{tf}"] = df
                
                if tf == "15":
                    history_starts.append(df['time'].min())
                    history_ends.append(df['time'].max())
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {path}: {e}")

    if not history_starts:
        logger.error("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç –≤ —Ñ–∞–π–ª–∞—Ö –∏—Å—Ç–æ—Ä–∏–∏!")
        return

    # 3. –†–ê–°–ß–ï–¢ –î–ê–¢ (–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ NaT)
    data_start = max(history_starts)
    data_end = min(history_ends)
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –¥–∞—Ç—ã –Ω–µ NaT
    if pd.isna(data_start) or pd.isna(data_end):
        logger.error("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –î–∞—Ç—ã –Ω–∞—á–∞–ª–∞ –∏–ª–∏ –∫–æ–Ω—Ü–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∫–∞–∫ NaT (Not a Time). –ü—Ä–æ–≤–µ—Ä—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ CSV.")
        return

    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Å—Ç–∞—Ä—Ç–æ–≤—ã–µ —Ç–æ—á–∫–∏ —Ç–æ–∂–µ –±–µ–∑ –ø–æ—è—Å–æ–≤
    sim_start = (data_start + timedelta(days=10)).replace(tzinfo=None)
    sim_end = data_end.replace(tzinfo=None)

    logger.info(f"‚è≥ –ü–µ—Ä–∏–æ–¥ —Ç–µ—Å—Ç–∞: {sim_start.date()} -> {sim_end.date()}")

    # 4. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø
    session_mock = BacktestSession(history)
    session_mock.sim_time = sim_start 
    
    bot = Orchestrator(
        session=session_mock, 
        ticker_list=tickers, 
        is_backtest=True, 
        db_path=test_db_path, 
        start_time=sim_start,
        params=params
    )
    
    bot.db.reset_database()
    bot.ws = session_mock 

    # –ü—Ä–æ–≥—Ä–µ–≤ –∏–Ω–¥–µ–∫—Å–æ–≤
    for key in history:
        idx = history[key]['time'].searchsorted(sim_start, side='left')
        setattr(session_mock, f"_idx_{key}", idx)

    logger.info("üöÄ –°–∏–º—É–ª—è—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞...")
    current_time = sim_start
    last_print_date = None
    start_perf = datetime.now()

    try:
        while current_time <= sim_end:
            session_mock.sim_time = current_time
            bot.set_sim_time(current_time)
            
            # –ë—ã—Å—Ç—Ä–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤
            for t in tickers:
                for tf in ["15", "60"]:
                    key = f"{t}_{tf}"
                    if key in history:
                        df = history[key]
                        curr_idx = getattr(session_mock, f"_idx_{key}")
                        while curr_idx < len(df) and df.iloc[curr_idx]['time'] <= current_time:
                            curr_idx += 1
                        setattr(session_mock, f"_idx_{key}", curr_idx)

            bot.update_open_trades_ws()

            if current_time.minute % 15 == 0:
                await bot.run_parallel_scan()
            
            current_time += timedelta(minutes=1)
            
            if current_time.date() != last_print_date:
                elapsed = datetime.now() - start_perf
                logger.info(f"üìà {current_time.date()} | –°–¥–µ–ª–æ–∫: {bot.db.get_active_trades_count('live')} | –ó–∞—Ç—Ä–∞—á–µ–Ω–æ: {str(elapsed).split('.')[0]}")
                last_print_date = current_time.date()

    except Exception as e:
        logger.exception(f"üí• –°–±–æ–π: {e}")

    logger.success(f"üèÅ –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù!")

if __name__ == "__main__":
    asyncio.run(run_backtest())